{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Ionosphere Data Problem\n",
    "\n",
    "### Dataset Description: \n",
    "\n",
    "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
    "\n",
    "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "- All 34 are continuous\n",
    "- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. This is a binary classification task.\n",
    "\n",
    " <br><br>\n",
    "\n",
    "<table border=\"1\"  cellpadding=\"6\">\n",
    "\t<tbody>\n",
    "        <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">351</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Physical</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
    "            <td><p class=\"normal\">Integer,Real</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
    "            <td><p class=\"normal\">34</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
    "            <td><p class=\"normal\">N/A</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\t\n",
    "    <tbody>\n",
    "    <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Classification</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t</tr>\n",
    "    </tbody>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORKFLOW :\n",
    "- Load Data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data:\n",
    "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/ionosphere_data.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset.\n",
    "df = pd.read_csv('ionosphere_data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the shape of the dataset \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear from the shape of the data that dataset is not a huge one. Only 351 records are available with 34 features/columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0         1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1         1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2         1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3         1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4         1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature1</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature2</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature3</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>0.87111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature4</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.01631</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature5</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>0.80920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature6</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.02280</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature7</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>0.72873</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature8</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.01471</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature9</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>0.68421</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature10</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>0.01829</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature11</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.476183</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>0.66798</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature12</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.155040</td>\n",
       "      <td>0.494817</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.065265</td>\n",
       "      <td>0.02825</td>\n",
       "      <td>0.482375</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature13</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.400801</td>\n",
       "      <td>0.622186</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.64407</td>\n",
       "      <td>0.955505</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature14</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.093414</td>\n",
       "      <td>0.494873</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.073725</td>\n",
       "      <td>0.03027</td>\n",
       "      <td>0.374860</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature15</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.344159</td>\n",
       "      <td>0.652828</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60194</td>\n",
       "      <td>0.919330</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature16</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.071132</td>\n",
       "      <td>0.458371</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.081705</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.308975</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature17</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.381949</td>\n",
       "      <td>0.618020</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.59091</td>\n",
       "      <td>0.935705</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature18</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.003617</td>\n",
       "      <td>0.496762</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.225690</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.195285</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature19</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.359390</td>\n",
       "      <td>0.626267</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57619</td>\n",
       "      <td>0.899265</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature20</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.024025</td>\n",
       "      <td>0.519076</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.234670</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.134370</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature21</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.336695</td>\n",
       "      <td>0.609828</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.49909</td>\n",
       "      <td>0.894865</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature22</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>0.518166</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.243870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.188760</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature23</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.362475</td>\n",
       "      <td>0.603767</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.53176</td>\n",
       "      <td>0.911235</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature24</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.057406</td>\n",
       "      <td>0.527456</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.366885</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.164630</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature25</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.55389</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature26</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>-0.01505</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature27</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>0.70824</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature28</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>-0.01769</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature29</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.49664</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature30</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature31</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.44277</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature32</th>\n",
       "      <td>351.0</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature33</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.40956</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature34</th>\n",
       "      <td>351.0</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>0.468337</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.165350</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.171660</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count      mean       std  min       25%      50%       75%  max\n",
       "feature1   351.0  0.891738  0.311155  0.0  1.000000  1.00000  1.000000  1.0\n",
       "feature2   351.0  0.000000  0.000000  0.0  0.000000  0.00000  0.000000  0.0\n",
       "feature3   351.0  0.641342  0.497708 -1.0  0.472135  0.87111  1.000000  1.0\n",
       "feature4   351.0  0.044372  0.441435 -1.0 -0.064735  0.01631  0.194185  1.0\n",
       "feature5   351.0  0.601068  0.519862 -1.0  0.412660  0.80920  1.000000  1.0\n",
       "feature6   351.0  0.115889  0.460810 -1.0 -0.024795  0.02280  0.334655  1.0\n",
       "feature7   351.0  0.550095  0.492654 -1.0  0.211310  0.72873  0.969240  1.0\n",
       "feature8   351.0  0.119360  0.520750 -1.0 -0.054840  0.01471  0.445675  1.0\n",
       "feature9   351.0  0.511848  0.507066 -1.0  0.087110  0.68421  0.953240  1.0\n",
       "feature10  351.0  0.181345  0.483851 -1.0 -0.048075  0.01829  0.534195  1.0\n",
       "feature11  351.0  0.476183  0.563496 -1.0  0.021120  0.66798  0.957895  1.0\n",
       "feature12  351.0  0.155040  0.494817 -1.0 -0.065265  0.02825  0.482375  1.0\n",
       "feature13  351.0  0.400801  0.622186 -1.0  0.000000  0.64407  0.955505  1.0\n",
       "feature14  351.0  0.093414  0.494873 -1.0 -0.073725  0.03027  0.374860  1.0\n",
       "feature15  351.0  0.344159  0.652828 -1.0  0.000000  0.60194  0.919330  1.0\n",
       "feature16  351.0  0.071132  0.458371 -1.0 -0.081705  0.00000  0.308975  1.0\n",
       "feature17  351.0  0.381949  0.618020 -1.0  0.000000  0.59091  0.935705  1.0\n",
       "feature18  351.0 -0.003617  0.496762 -1.0 -0.225690  0.00000  0.195285  1.0\n",
       "feature19  351.0  0.359390  0.626267 -1.0  0.000000  0.57619  0.899265  1.0\n",
       "feature20  351.0 -0.024025  0.519076 -1.0 -0.234670  0.00000  0.134370  1.0\n",
       "feature21  351.0  0.336695  0.609828 -1.0  0.000000  0.49909  0.894865  1.0\n",
       "feature22  351.0  0.008296  0.518166 -1.0 -0.243870  0.00000  0.188760  1.0\n",
       "feature23  351.0  0.362475  0.603767 -1.0  0.000000  0.53176  0.911235  1.0\n",
       "feature24  351.0 -0.057406  0.527456 -1.0 -0.366885  0.00000  0.164630  1.0\n",
       "feature25  351.0  0.396135  0.578451 -1.0  0.000000  0.55389  0.905240  1.0\n",
       "feature26  351.0 -0.071187  0.508495 -1.0 -0.332390 -0.01505  0.156765  1.0\n",
       "feature27  351.0  0.541641  0.516205 -1.0  0.286435  0.70824  0.999945  1.0\n",
       "feature28  351.0 -0.069538  0.550025 -1.0 -0.443165 -0.01769  0.153535  1.0\n",
       "feature29  351.0  0.378445  0.575886 -1.0  0.000000  0.49664  0.883465  1.0\n",
       "feature30  351.0 -0.027907  0.507974 -1.0 -0.236885  0.00000  0.154075  1.0\n",
       "feature31  351.0  0.352514  0.571483 -1.0  0.000000  0.44277  0.857620  1.0\n",
       "feature32  351.0 -0.003794  0.513574 -1.0 -0.242595  0.00000  0.200120  1.0\n",
       "feature33  351.0  0.349364  0.522663 -1.0  0.000000  0.40956  0.813765  1.0\n",
       "feature34  351.0  0.014480  0.468337 -1.0 -0.165350  0.00000  0.171660  1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1\n",
      "2\n",
      "feature2\n",
      "1\n",
      "feature3\n",
      "219\n",
      "feature4\n",
      "269\n",
      "feature5\n",
      "204\n",
      "feature6\n",
      "259\n",
      "feature7\n",
      "231\n",
      "feature8\n",
      "260\n",
      "feature9\n",
      "244\n",
      "feature10\n",
      "267\n",
      "feature11\n",
      "246\n",
      "feature12\n",
      "269\n",
      "feature13\n",
      "238\n",
      "feature14\n",
      "266\n",
      "feature15\n",
      "234\n",
      "feature16\n",
      "270\n",
      "feature17\n",
      "254\n",
      "feature18\n",
      "280\n",
      "feature19\n",
      "254\n",
      "feature20\n",
      "266\n",
      "feature21\n",
      "248\n",
      "feature22\n",
      "265\n",
      "feature23\n",
      "248\n",
      "feature24\n",
      "264\n",
      "feature25\n",
      "256\n",
      "feature26\n",
      "273\n",
      "feature27\n",
      "256\n",
      "feature28\n",
      "281\n",
      "feature29\n",
      "244\n",
      "feature30\n",
      "266\n",
      "feature31\n",
      "243\n",
      "feature32\n",
      "263\n",
      "feature33\n",
      "245\n",
      "feature34\n",
      "263\n",
      "label\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for feature in df:\n",
    "    print(feature)\n",
    "    print(len(df[feature].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['feature2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[1], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>0.50874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>0.73082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>0.52798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature3  feature4  feature5  feature6  feature7  feature8  \\\n",
       "0         1   0.99539  -0.05889   0.85243   0.02306   0.83398  -0.37708   \n",
       "1         1   1.00000  -0.18829   0.93035  -0.36156  -0.10868  -0.93597   \n",
       "2         1   1.00000  -0.03365   1.00000   0.00485   1.00000  -0.12062   \n",
       "3         1   1.00000  -0.45161   1.00000   1.00000   0.71216  -1.00000   \n",
       "4         1   1.00000  -0.02401   0.94140   0.06531   0.92106  -0.23255   \n",
       "\n",
       "   feature9  feature10  feature11  ...  feature26  feature27  feature28  \\\n",
       "0   1.00000    0.03760    0.85243  ...   -0.51171    0.41078   -0.46168   \n",
       "1   1.00000   -0.04549    0.50874  ...   -0.26569   -0.20468   -0.18401   \n",
       "2   0.88965    0.01198    0.73082  ...   -0.40220    0.58984   -0.22145   \n",
       "3   0.00000    0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4   0.77152   -0.16399    0.52798  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 34 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   feature1   351 non-null    int64  \n",
      " 1   feature3   351 non-null    float64\n",
      " 2   feature4   351 non-null    float64\n",
      " 3   feature5   351 non-null    float64\n",
      " 4   feature6   351 non-null    float64\n",
      " 5   feature7   351 non-null    float64\n",
      " 6   feature8   351 non-null    float64\n",
      " 7   feature9   351 non-null    float64\n",
      " 8   feature10  351 non-null    float64\n",
      " 9   feature11  351 non-null    float64\n",
      " 10  feature12  351 non-null    float64\n",
      " 11  feature13  351 non-null    float64\n",
      " 12  feature14  351 non-null    float64\n",
      " 13  feature15  351 non-null    float64\n",
      " 14  feature16  351 non-null    float64\n",
      " 15  feature17  351 non-null    float64\n",
      " 16  feature18  351 non-null    float64\n",
      " 17  feature19  351 non-null    float64\n",
      " 18  feature20  351 non-null    float64\n",
      " 19  feature21  351 non-null    float64\n",
      " 20  feature22  351 non-null    float64\n",
      " 21  feature23  351 non-null    float64\n",
      " 22  feature24  351 non-null    float64\n",
      " 23  feature25  351 non-null    float64\n",
      " 24  feature26  351 non-null    float64\n",
      " 25  feature27  351 non-null    float64\n",
      " 26  feature28  351 non-null    float64\n",
      " 27  feature29  351 non-null    float64\n",
      " 28  feature30  351 non-null    float64\n",
      " 29  feature31  351 non-null    float64\n",
      " 30  feature32  351 non-null    float64\n",
      " 31  feature33  351 non-null    float64\n",
      " 32  feature34  351 non-null    float64\n",
      " 33  label      351 non-null    object \n",
      "dtypes: float64(32), int64(1), object(1)\n",
      "memory usage: 93.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for feature in df:\\n    print(feature)\\n    df[feature].hist()\\n    plt.show()'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for feature in df:\n",
    "    print(feature)\n",
    "    df[feature].hist()\n",
    "    plt.show()'''\n",
    "\n",
    "# df.hist()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>0.476183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.014480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>0.563496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>0.468337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>0.021120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871110</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.728730</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.684210</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>0.667980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553890</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>0.708240</td>\n",
       "      <td>-0.017690</td>\n",
       "      <td>0.496640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409560</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>0.957895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>0.171660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature1    feature3    feature4    feature5    feature6    feature7  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.891738    0.641342    0.044372    0.601068    0.115889    0.550095   \n",
       "std      0.311155    0.497708    0.441435    0.519862    0.460810    0.492654   \n",
       "min      0.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      1.000000    0.472135   -0.064735    0.412660   -0.024795    0.211310   \n",
       "50%      1.000000    0.871110    0.016310    0.809200    0.022800    0.728730   \n",
       "75%      1.000000    1.000000    0.194185    1.000000    0.334655    0.969240   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         feature8    feature9   feature10   feature11  ...   feature25  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  ...  351.000000   \n",
       "mean     0.119360    0.511848    0.181345    0.476183  ...    0.396135   \n",
       "std      0.520750    0.507066    0.483851    0.563496  ...    0.578451   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
       "25%     -0.054840    0.087110   -0.048075    0.021120  ...    0.000000   \n",
       "50%      0.014710    0.684210    0.018290    0.667980  ...    0.553890   \n",
       "75%      0.445675    0.953240    0.534195    0.957895  ...    0.905240   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "        feature26   feature27   feature28   feature29   feature30   feature31  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean    -0.071187    0.541641   -0.069538    0.378445   -0.027907    0.352514   \n",
       "std      0.508495    0.516205    0.550025    0.575886    0.507974    0.571483   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%     -0.332390    0.286435   -0.443165    0.000000   -0.236885    0.000000   \n",
       "50%     -0.015050    0.708240   -0.017690    0.496640    0.000000    0.442770   \n",
       "75%      0.156765    0.999945    0.153535    0.883465    0.154075    0.857620   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        feature32   feature33   feature34  \n",
       "count  351.000000  351.000000  351.000000  \n",
       "mean    -0.003794    0.349364    0.014480  \n",
       "std      0.513574    0.522663    0.468337  \n",
       "min     -1.000000   -1.000000   -1.000000  \n",
       "25%     -0.242595    0.000000   -0.165350  \n",
       "50%      0.000000    0.409560    0.000000  \n",
       "75%      0.200120    0.813765    0.171660  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0\n",
       "feature3     0\n",
       "feature4     0\n",
       "feature5     0\n",
       "feature6     0\n",
       "feature7     0\n",
       "feature8     0\n",
       "feature9     0\n",
       "feature10    0\n",
       "feature11    0\n",
       "feature12    0\n",
       "feature13    0\n",
       "feature14    0\n",
       "feature15    0\n",
       "feature16    0\n",
       "feature17    0\n",
       "feature18    0\n",
       "feature19    0\n",
       "feature20    0\n",
       "feature21    0\n",
       "feature22    0\n",
       "feature23    0\n",
       "feature24    0\n",
       "feature25    0\n",
       "feature26    0\n",
       "feature27    0\n",
       "feature28    0\n",
       "feature29    0\n",
       "feature30    0\n",
       "feature31    0\n",
       "feature32    0\n",
       "feature33    0\n",
       "feature34    0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = [1 if lbl == 'g' else 0 for lbl in df['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.sample(frac= 0.6, random_state=125)\n",
    "test_data = df.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data.iloc[:,-1]\n",
    "train_data = train_data.iloc[:,0:-1]\n",
    "test_label = test_data.iloc[:,-1]\n",
    "test_data = test_data.iloc[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns= 'label', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.08013</td>\n",
       "      <td>0.96775</td>\n",
       "      <td>-0.00482</td>\n",
       "      <td>0.96683</td>\n",
       "      <td>-0.00722</td>\n",
       "      <td>0.87980</td>\n",
       "      <td>-0.03923</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98164</td>\n",
       "      <td>0.02003</td>\n",
       "      <td>0.93772</td>\n",
       "      <td>-0.03034</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.05843</td>\n",
       "      <td>0.92774</td>\n",
       "      <td>-0.03464</td>\n",
       "      <td>0.92226</td>\n",
       "      <td>-0.03673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.14754</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.04918</td>\n",
       "      <td>0.57377</td>\n",
       "      <td>-0.01639</td>\n",
       "      <td>0.65574</td>\n",
       "      <td>0.01639</td>\n",
       "      <td>0.85246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31148</td>\n",
       "      <td>-0.34426</td>\n",
       "      <td>0.52385</td>\n",
       "      <td>-0.20325</td>\n",
       "      <td>0.32787</td>\n",
       "      <td>-0.03279</td>\n",
       "      <td>0.27869</td>\n",
       "      <td>-0.44262</td>\n",
       "      <td>0.49180</td>\n",
       "      <td>-0.06557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>0.89706</td>\n",
       "      <td>0.38235</td>\n",
       "      <td>0.91176</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>0.74265</td>\n",
       "      <td>0.67647</td>\n",
       "      <td>0.45588</td>\n",
       "      <td>0.77941</td>\n",
       "      <td>0.19118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.74265</td>\n",
       "      <td>-0.12500</td>\n",
       "      <td>-0.67925</td>\n",
       "      <td>-0.24131</td>\n",
       "      <td>-0.55147</td>\n",
       "      <td>-0.42647</td>\n",
       "      <td>-0.44118</td>\n",
       "      <td>-0.50735</td>\n",
       "      <td>-0.28676</td>\n",
       "      <td>-0.56618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>0.84557</td>\n",
       "      <td>-0.08580</td>\n",
       "      <td>-0.31745</td>\n",
       "      <td>-0.80553</td>\n",
       "      <td>-0.08961</td>\n",
       "      <td>-0.56435</td>\n",
       "      <td>0.80648</td>\n",
       "      <td>0.04576</td>\n",
       "      <td>0.89514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78932</td>\n",
       "      <td>-0.03718</td>\n",
       "      <td>0.70882</td>\n",
       "      <td>-0.25288</td>\n",
       "      <td>0.77884</td>\n",
       "      <td>-0.14109</td>\n",
       "      <td>-0.21354</td>\n",
       "      <td>-0.78170</td>\n",
       "      <td>-0.18494</td>\n",
       "      <td>-0.59867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.77941</td>\n",
       "      <td>-0.99265</td>\n",
       "      <td>0.80882</td>\n",
       "      <td>0.55147</td>\n",
       "      <td>-0.41912</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature1  feature3  feature4  feature5  feature6  feature7  feature8  \\\n",
       "270         1   1.00000   0.08013   0.96775  -0.00482   0.96683  -0.00722   \n",
       "116         1   1.00000  -0.14754   1.00000   0.04918   0.57377  -0.01639   \n",
       "135         1   0.89706   0.38235   0.91176   0.37500   0.74265   0.67647   \n",
       "91          1   0.84557  -0.08580  -0.31745  -0.80553  -0.08961  -0.56435   \n",
       "100         1   1.00000  -1.00000   0.00000   0.00000   0.77941  -0.99265   \n",
       "\n",
       "     feature9  feature10  feature11  ...  feature25  feature26  feature27  \\\n",
       "270   0.87980   -0.03923    1.00000  ...    0.98164    0.02003    0.93772   \n",
       "116   0.65574    0.01639    0.85246  ...    0.31148   -0.34426    0.52385   \n",
       "135   0.45588    0.77941    0.19118  ...   -0.74265   -0.12500   -0.67925   \n",
       "91    0.80648    0.04576    0.89514  ...    0.78932   -0.03718    0.70882   \n",
       "100   0.80882    0.55147   -0.41912  ...   -1.00000   -1.00000   -1.00000   \n",
       "\n",
       "     feature28  feature29  feature30  feature31  feature32  feature33  \\\n",
       "270   -0.03034    1.00000   -0.05843    0.92774   -0.03464    0.92226   \n",
       "116   -0.20325    0.32787   -0.03279    0.27869   -0.44262    0.49180   \n",
       "135   -0.24131   -0.55147   -0.42647   -0.44118   -0.50735   -0.28676   \n",
       "91    -0.25288    0.77884   -0.14109   -0.21354   -0.78170   -0.18494   \n",
       "100   -1.00000    1.00000   -1.00000    1.00000   -1.00000    0.00000   \n",
       "\n",
       "     feature34  \n",
       "270   -0.03673  \n",
       "116   -0.06557  \n",
       "135   -0.56618  \n",
       "91    -0.59867  \n",
       "100    0.00000  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270    1\n",
       "116    0\n",
       "135    1\n",
       "91     0\n",
       "100    0\n",
       "      ..\n",
       "213    1\n",
       "161    1\n",
       "141    1\n",
       "59     0\n",
       "113    1\n",
       "Name: label, Length: 211, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standardized the Input Variables. **Hint**: Centeralized the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "# train_mean = train_data.mean()\n",
    "# train_data -= train_mean\n",
    "# train_std = train_data.std()\n",
    "# train_data /= train_std\n",
    "# test_data -= train_mean\n",
    "# test_data /= train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encode labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Shuffle the data if needed.\n",
    "- Split into 60 and 40 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now sample the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211, 33)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 33)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_label.sum()/len(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_label.to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_label.to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set = np.array(train_set.as_matrix())\n",
    "#train_label = np.array(pd.DataFrame(train_label).as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(type(train_label))\n",
    "print(type(test_data))\n",
    "print(type(test_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float32\n",
      "float32\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.dtype)\n",
    "print(train_label.dtype)\n",
    "print(test_label.dtype)\n",
    "print(test_data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model : 1 hidden layers including 16 unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,  activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               4352      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile(optimizer = 'RMSprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train the Model with Epochs (100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "5/5 [==============================] - 2s 234ms/step - loss: 0.7176 - accuracy: 0.4707 - val_loss: 0.5714 - val_accuracy: 0.7170\n",
      "Epoch 2/75\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5853 - accuracy: 0.7047 - val_loss: 0.5036 - val_accuracy: 0.7358\n",
      "Epoch 3/75\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5168 - accuracy: 0.7414 - val_loss: 0.4577 - val_accuracy: 0.7925\n",
      "Epoch 4/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4792 - accuracy: 0.7623 - val_loss: 0.4243 - val_accuracy: 0.8302\n",
      "Epoch 5/75\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4126 - accuracy: 0.8413 - val_loss: 0.3935 - val_accuracy: 0.9057\n",
      "Epoch 6/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3994 - accuracy: 0.8922 - val_loss: 0.3590 - val_accuracy: 0.9057\n",
      "Epoch 7/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3508 - accuracy: 0.8860 - val_loss: 0.3341 - val_accuracy: 0.9057\n",
      "Epoch 8/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3296 - accuracy: 0.8938 - val_loss: 0.3193 - val_accuracy: 0.9245\n",
      "Epoch 9/75\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2997 - accuracy: 0.9300 - val_loss: 0.2922 - val_accuracy: 0.9245\n",
      "Epoch 10/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2574 - accuracy: 0.9341 - val_loss: 0.2768 - val_accuracy: 0.9245\n",
      "Epoch 11/75\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2334 - accuracy: 0.9318 - val_loss: 0.2589 - val_accuracy: 0.9434\n",
      "Epoch 12/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2726 - accuracy: 0.9281 - val_loss: 0.2470 - val_accuracy: 0.9434\n",
      "Epoch 13/75\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2203 - accuracy: 0.9459 - val_loss: 0.2378 - val_accuracy: 0.9434\n",
      "Epoch 14/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2179 - accuracy: 0.9506 - val_loss: 0.2298 - val_accuracy: 0.9434\n",
      "Epoch 15/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1799 - accuracy: 0.9683 - val_loss: 0.2263 - val_accuracy: 0.9434\n",
      "Epoch 16/75\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2005 - accuracy: 0.9579 - val_loss: 0.2317 - val_accuracy: 0.9434\n",
      "Epoch 17/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1656 - accuracy: 0.9554 - val_loss: 0.2279 - val_accuracy: 0.9434\n",
      "Epoch 18/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1847 - accuracy: 0.9622 - val_loss: 0.2265 - val_accuracy: 0.9434\n",
      "Epoch 19/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1745 - accuracy: 0.9553 - val_loss: 0.2199 - val_accuracy: 0.9434\n",
      "Epoch 20/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1703 - accuracy: 0.9713 - val_loss: 0.2169 - val_accuracy: 0.9434\n",
      "Epoch 21/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1426 - accuracy: 0.9656 - val_loss: 0.2207 - val_accuracy: 0.9434\n",
      "Epoch 22/75\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1535 - accuracy: 0.9557 - val_loss: 0.2257 - val_accuracy: 0.9434\n",
      "Epoch 23/75\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1402 - accuracy: 0.9660 - val_loss: 0.2223 - val_accuracy: 0.9434\n",
      "Epoch 24/75\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1416 - accuracy: 0.9527 - val_loss: 0.2294 - val_accuracy: 0.9623\n",
      "Epoch 25/75\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1387 - accuracy: 0.9558 - val_loss: 0.2247 - val_accuracy: 0.9434\n",
      "Epoch 26/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1346 - accuracy: 0.9678 - val_loss: 0.2252 - val_accuracy: 0.9434\n",
      "Epoch 27/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1493 - accuracy: 0.9668 - val_loss: 0.2255 - val_accuracy: 0.9623\n",
      "Epoch 28/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0922 - accuracy: 0.9747 - val_loss: 0.2310 - val_accuracy: 0.9623\n",
      "Epoch 29/75\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1066 - accuracy: 0.9795 - val_loss: 0.2333 - val_accuracy: 0.9434\n",
      "Epoch 30/75\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0951 - accuracy: 0.9781 - val_loss: 0.2307 - val_accuracy: 0.9623\n",
      "Epoch 31/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0946 - accuracy: 0.9722 - val_loss: 0.2393 - val_accuracy: 0.9434\n",
      "Epoch 32/75\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0747 - accuracy: 0.9893 - val_loss: 0.2484 - val_accuracy: 0.9434\n",
      "Epoch 33/75\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0890 - accuracy: 0.9720 - val_loss: 0.2467 - val_accuracy: 0.9623\n",
      "Epoch 34/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0539 - accuracy: 0.9859 - val_loss: 0.2500 - val_accuracy: 0.9434\n",
      "Epoch 35/75\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0710 - accuracy: 0.9785 - val_loss: 0.2548 - val_accuracy: 0.9623\n",
      "Epoch 36/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0521 - accuracy: 0.9897 - val_loss: 0.2582 - val_accuracy: 0.9623\n",
      "Epoch 37/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0818 - accuracy: 0.9733 - val_loss: 0.2714 - val_accuracy: 0.9623\n",
      "Epoch 38/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1010 - accuracy: 0.9613 - val_loss: 0.2686 - val_accuracy: 0.9434\n",
      "Epoch 39/75\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0735 - accuracy: 0.9738 - val_loss: 0.2666 - val_accuracy: 0.9623\n",
      "Epoch 40/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0977 - accuracy: 0.9681 - val_loss: 0.2753 - val_accuracy: 0.9623\n",
      "Epoch 41/75\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0540 - accuracy: 0.9741 - val_loss: 0.2772 - val_accuracy: 0.9623\n",
      "Epoch 42/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0576 - accuracy: 0.9914 - val_loss: 0.2847 - val_accuracy: 0.9623\n",
      "Epoch 43/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0432 - accuracy: 0.9867 - val_loss: 0.2876 - val_accuracy: 0.9623\n",
      "Epoch 44/75\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0602 - accuracy: 0.9772 - val_loss: 0.2886 - val_accuracy: 0.9623\n",
      "Epoch 45/75\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1067 - accuracy: 0.9663 - val_loss: 0.2906 - val_accuracy: 0.9623\n",
      "Epoch 46/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1002 - accuracy: 0.9819 - val_loss: 0.2844 - val_accuracy: 0.9623\n",
      "Epoch 47/75\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0712 - accuracy: 0.9747 - val_loss: 0.2796 - val_accuracy: 0.9434\n",
      "Epoch 48/75\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0538 - accuracy: 0.9914 - val_loss: 0.2817 - val_accuracy: 0.9623\n",
      "Epoch 49/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0319 - accuracy: 0.9966 - val_loss: 0.2860 - val_accuracy: 0.9623\n",
      "Epoch 50/75\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0490 - accuracy: 0.9870 - val_loss: 0.2863 - val_accuracy: 0.9623\n",
      "Epoch 51/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0362 - accuracy: 0.9854 - val_loss: 0.2990 - val_accuracy: 0.9623\n",
      "Epoch 52/75\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0328 - accuracy: 0.9932 - val_loss: 0.2930 - val_accuracy: 0.9623\n",
      "Epoch 53/75\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0526 - accuracy: 0.9901 - val_loss: 0.3027 - val_accuracy: 0.9434\n",
      "Epoch 54/75\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0399 - accuracy: 0.9819 - val_loss: 0.3090 - val_accuracy: 0.9623\n",
      "Epoch 55/75\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0228 - accuracy: 0.9979 - val_loss: 0.3109 - val_accuracy: 0.9623\n",
      "Epoch 56/75\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0218 - accuracy: 0.9979 - val_loss: 0.3132 - val_accuracy: 0.9623\n",
      "Epoch 57/75\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0368 - accuracy: 0.9979 - val_loss: 0.3072 - val_accuracy: 0.9623\n",
      "Epoch 58/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0331 - accuracy: 0.9888 - val_loss: 0.2995 - val_accuracy: 0.9623\n",
      "Epoch 59/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0681 - accuracy: 0.9819 - val_loss: 0.2972 - val_accuracy: 0.9623\n",
      "Epoch 60/75\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9623\n",
      "Epoch 61/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.3155 - val_accuracy: 0.9623\n",
      "Epoch 62/75\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0456 - accuracy: 0.9870 - val_loss: 0.3303 - val_accuracy: 0.9623\n",
      "Epoch 63/75\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.00 - 0s 14ms/step - loss: 0.0248 - accuracy: 0.9914 - val_loss: 0.3341 - val_accuracy: 0.9434\n",
      "Epoch 64/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.9623\n",
      "Epoch 65/75\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0270 - accuracy: 0.9922 - val_loss: 0.3334 - val_accuracy: 0.9623\n",
      "Epoch 66/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0304 - accuracy: 0.9914 - val_loss: 0.3172 - val_accuracy: 0.9623\n",
      "Epoch 67/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.3318 - val_accuracy: 0.9623\n",
      "Epoch 68/75\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.9623\n",
      "Epoch 69/75\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.9623\n",
      "Epoch 70/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.9623\n",
      "Epoch 71/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.3547 - val_accuracy: 0.9623\n",
      "Epoch 72/75\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.9623\n",
      "Epoch 73/75\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.9623\n",
      "Epoch 74/75\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0354 - accuracy: 0.9922 - val_loss: 0.3277 - val_accuracy: 0.9623\n",
      "Epoch 75/75\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9623\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_label, validation_split=0.25, epochs= 75, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3TUlEQVR4nO3deXxU9dX48c9JCEsIoARwIRKgIggCAQKiIOJWxQVwewSRRVREbF1oVSxW+Wl5avvYSq1YiwvYRyy1LhQVRVERXJ5KVEQQUFCCqagssglCCOf3x/eGTIbZkszNTGbO+/WaV2bu3LlzJoF75n6X8xVVxRhjTPrKSHQAxhhjEssSgTHGpDlLBMYYk+YsERhjTJqzRGCMMWnOEoExxqQ5SwQmrkTkZREZHe99E0lE1ovImT4cV0XkWO/+wyLy61j2rcb7jBCRV6sbZ4TjDhSRkngf19S+eokOwCSeiOwKeJgN7AXKvMfXqursWI+lqoP82DfVqer4eBxHRNoCXwJZqrrfO/ZsIOa/oUk/lggMqppTfl9E1gNXq+rC4P1EpF75ycUYkzqsaciEVX7pLyK3icg3wEwROVxEXhSRTSLyvXc/L+A1i0Tkau/+GBF5W0Tu8/b9UkQGVXPfdiKyWER2ishCEZkuIk+GiTuWGO8RkXe8470qIi0Cnh8pIsUiskVEJkf4/fQVkW9EJDNg24Uisty730dE3hORbSKyUUQeFJH6YY41S0R+E/D4Fu81X4vI2KB9zxORj0Rkh4h8JSJTAp5e7P3cJiK7ROSk8t9twOtPFpGlIrLd+3lyrL+bSETkeO/120RkpYgMDnjuXBH51Dvmf0Tkl972Ft7fZ5uIbBWRJSJi56VaZr9wE82RQHMgHxiH+zcz03vcBtgDPBjh9ScCa4AWwO+Bx0REqrHvU8D7QC4wBRgZ4T1jifFy4EqgFVAfKD8xdQb+4h3/aO/98ghBVf8P+AE4Pei4T3n3y4Cbvc9zEnAGMCFC3HgxnOPFcxbQAQjun/gBGAUcBpwHXCciQ73nBng/D1PVHFV9L+jYzYGXgAe8z/ZH4CURyQ36DIf8bqLEnAW8ALzqve7nwGwR6ejt8hiumbEJcALwhrf9F0AJ0BI4AvgVYHVvapklAhPNAeAuVd2rqntUdYuqPququ1V1JzAVODXC64tV9RFVLQOeAI7C/YePeV8RaQP0Bu5U1X2q+jYwL9wbxhjjTFX9TFX3AE8DBd72S4AXVXWxqu4Ffu39DsL5OzAcQESaAOd621DVD1T1/1R1v6quB/4aIo5Q/suLb4Wq/oBLfIGfb5GqfqKqB1R1ufd+sRwXXOL4XFX/14vr78Bq4IKAfcL9biLpC+QA93p/ozeAF/F+N0Ap0FlEmqrq96r6YcD2o4B8VS1V1SVqBdBqnSUCE80mVf2x/IGIZIvIX72mkx24pojDAptHgnxTfkdVd3t3c6q479HA1oBtAF+FCzjGGL8JuL87IKajA4/tnYi3hHsv3Lf/i0SkAXAR8KGqFntxHOc1e3zjxfHfuKuDaCrFABQHfb4TReRNr+lrOzA+xuOWH7s4aFsx0DrgcbjfTdSYVTUwaQYe92JckiwWkbdE5CRv+/8Aa4FXReQLEZkU28cw8WSJwEQT/O3sF0BH4ERVbUpFU0S45p542Ag0F5HsgG3HRNi/JjFuDDy295654XZW1U9xJ7xBVG4WAtfEtBro4MXxq+rEgGveCvQU7oroGFVtBjwccNxo36a/xjWZBWoD/CeGuKId95ig9v2Dx1XVpao6BNdsNBd3pYGq7lTVX6hqe9xVyUQROaOGsZgqskRgqqoJrs19m9fefJffb+h9wy4CpohIfe/b5AURXlKTGJ8BzheR/l7H7t1E/3/yFHADLuH8MyiOHcAuEekEXBdjDE8DY0Sks5eIguNvgrtC+lFE+uASULlNuKas9mGOPR84TkQuF5F6InIZ0BnXjFMT/8b1XdwqIlkiMhD3N5rj/c1GiEgzVS3F/U7KAETkfBE51usLKt9eFvIdjG8sEZiqmgY0AjYD/we8UkvvOwLX4boF+A3wD9x8h1CmUc0YVXUlcD3u5L4R+B7XmRnJ34GBwBuqujlg+y9xJ+mdwCNezLHE8LL3Gd7ANZu8EbTLBOBuEdkJ3In37dp77W5cn8g73kicvkHH3gKcj7tq2gLcCpwfFHeVqeo+YDDuymgz8BAwSlVXe7uMBNZ7TWTjgSu87R2AhcAu4D3gIVVdVJNYTNWJ9cuYukhE/gGsVlXfr0iMSXV2RWDqBBHpLSI/EZEMb3jlEFxbszGmhmxmsakrjgSew3XclgDXqepHiQ3JmNRgTUPGGJPmrGnIGGPSnK9NQ15b7p+ATOBRVb036PlbcKNBymM5HmipqlvDHbNFixbatm1bfwI2xpgU9cEHH2xW1ZahnvOtacibxfkZrl5KCbAUGO5NwAm1/wXAzap6eqjnyxUWFmpRUVG8wzXGmJQmIh+oamGo5/xsGuoDrFXVL7wxxnNwIz3CGY5Xo8UYY0zt8TMRtKZyvZQSKtczOcibPXkO8GyY58eJSJGIFG3atCnugRpjTDrzMxGEqqkSrh3qAuCdcH0DqjpDVQtVtbBly5BNXMYYY6rJz87iEioXzsrDFaYKZRjWLGRM0iotLaWkpIQff/wx+s4moRo2bEheXh5ZWVkxv8bPRLAU6CAi7XAVCIdRuTgWACLSDFdL/Yrg54wxyaGkpIQmTZrQtm1bwq8rZBJNVdmyZQslJSW0a9cu5tf51jTkrW37M2ABsAp4WlVXish4EQlcqPtC4FWv7rsvZs+Gtm0hI8P9nG3LeBtTJT/++CO5ubmWBJKciJCbm1vlKzdf5xGo6nxc2dvAbQ8HPZ4FzPIrhtmzYdw42O0taVJc7B4DjBgR/nXGmMosCdQN1fk7pfzM4smTK5JAud273XZjjDFpkAg2bKjadmNM8tmyZQsFBQUUFBRw5JFH0rp164OP9+3bF/G1RUVF3HDDDVHf4+STT45LrIsWLeL888+Py7FqS8ongjbBi/xF2W6Mqbl498vl5uaybNkyli1bxvjx47n55psPPq5fvz779+8P+9rCwkIeeOCBqO/x7rvv1izIOizlE8HUqZCdXXlbdrbbboyJv/J+ueJiUK3ol4v3II0xY8YwceJETjvtNG677Tbef/99Tj75ZHr06MHJJ5/MmjVrgMrf0KdMmcLYsWMZOHAg7du3r5QgcnJyDu4/cOBALrnkEjp16sSIESMoL8Uzf/58OnXqRP/+/bnhhhuifvPfunUrQ4cOpVu3bvTt25fly5cD8NZbbx28ounRowc7d+5k48aNDBgwgIKCAk444QSWLFkS319YBCm/HkF5h/Dkya45qE0blwSso9gYf0Tql4v3/7vPPvuMhQsXkpmZyY4dO1i8eDH16tVj4cKF/OpXv+LZZw8tVrB69WrefPNNdu7cSceOHbnuuusOGXP/0UcfsXLlSo4++mj69evHO++8Q2FhIddeey2LFy+mXbt2DB8+PGp8d911Fz169GDu3Lm88cYbjBo1imXLlnHfffcxffp0+vXrx65du2jYsCEzZszg7LPPZvLkyZSVlbE7+Jfoo5RPBOD+8dmJ35jaUZv9cpdeeimZmZkAbN++ndGjR/P5558jIpSWloZ8zXnnnUeDBg1o0KABrVq14ttvvyUvL6/SPn369Dm4raCggPXr15OTk0P79u0Pjs8fPnw4M2bMiBjf22+/fTAZnX766WzZsoXt27fTr18/Jk6cyIgRI7jooovIy8ujd+/ejB07ltLSUoYOHUpBQUFNfjVVkvJNQ8aY2lWb/XKNGzc+eP/Xv/41p512GitWrOCFF14IO5a+QYMGB+9nZmaG7F8ItU91KjWHeo2IMGnSJB599FH27NlD3759Wb16NQMGDGDx4sW0bt2akSNH8re//a3K71ddlgiMMXGVqH657du307q1q2s5a9asuB+/U6dOfPHFF6xfvx6Af/zjH1FfM2DAAGZ7nSOLFi2iRYsWNG3alHXr1tG1a1duu+02CgsLWb16NcXFxbRq1YprrrmGq666ig8//DDunyEcSwTGmLgaMQJmzID8fBBxP2fM8L959tZbb+X222+nX79+lJWVxf34jRo14qGHHuKcc86hf//+HHHEETRr1izia6ZMmUJRURHdunVj0qRJPPHEEwBMmzaNE044ge7du9OoUSMGDRrEokWLDnYeP/vss9x4441x/wzh1Lk1i21hGmNq36pVqzj++OMTHUbC7dq1i5ycHFSV66+/ng4dOnDzzTcnOqxDhPp7JWphGmOMSSmPPPIIBQUFdOnShe3bt3PttdcmOqS4SItRQ8YYEw8333xzUl4B1JRdERhjTJqzRGCMMWnOEoExxqQ5SwTGGJPmLBEYY5LewIEDWbBgQaVt06ZNY8KECRFfUz7U/Nxzz2Xbtm2H7DNlyhTuu+++iO89d+5cPv3004OP77zzThYuXFiF6ENLpnLVlgiMMUlv+PDhzJkzp9K2OXPmxFT4DVzV0MMOO6xa7x2cCO6++27OPPPMah0rWVkiMMYkvUsuuYQXX3yRvXv3ArB+/Xq+/vpr+vfvz3XXXUdhYSFdunThrrvuCvn6tm3bsnnzZgCmTp1Kx44dOfPMMw+WqgY3R6B37950796diy++mN27d/Puu+8yb948brnlFgoKCli3bh1jxozhmWeeAeD111+nR48edO3albFjxx6Mr23bttx111307NmTrl27snr16oifL9Hlqm0egTGmSm66CZYti+8xCwpg2rTwz+fm5tKnTx9eeeUVhgwZwpw5c7jssssQEaZOnUrz5s0pKyvjjDPOYPny5XTr1i3kcT744APmzJnDRx99xP79++nZsye9evUC4KKLLuKaa64B4I477uCxxx7j5z//OYMHD+b888/nkksuqXSsH3/8kTFjxvD6669z3HHHMWrUKP7yl79w0003AdCiRQs+/PBDHnroIe677z4effTRsJ8v0eWq7YrAGFMnBDYPBTYLPf300/Ts2ZMePXqwcuXKSs04wZYsWcKFF15IdnY2TZs2ZfDgwQefW7FiBaeccgpdu3Zl9uzZrFy5MmI8a9asoV27dhx33HEAjB49msWLFx98/qKLLgKgV69eBwvVhfP2228zcuRIIHS56gceeIBt27ZRr149evfuzcyZM5kyZQqffPIJTZo0iXjsWPh6RSAi5wB/AjKBR1X13hD7DASmAVnAZlU91c+YjDE1E+mbu5+GDh3KxIkT+fDDD9mzZw89e/bkyy+/5L777mPp0qUcfvjhjBkzJmz56XIiEnL7mDFjmDt3Lt27d2fWrFksWrQo4nGi1WkrL2UdrtR1tGOVl6s+77zzmD9/Pn379mXhwoUHy1W/9NJLjBw5kltuuYVRo0ZFPH40vl0RiEgmMB0YBHQGhotI56B9DgMeAgarahfgUr/iMcbUbTk5OQwcOJCxY8cevBrYsWMHjRs3plmzZnz77be8/PLLEY8xYMAAnn/+efbs2cPOnTt54YUXDj63c+dOjjrqKEpLSw+WjgZo0qQJO3fuPORYnTp1Yv369axduxaA//3f/+XUU6v3PTbR5ar9vCLoA6xV1S8ARGQOMAQIvG67HHhOVTcAqOp3PsZjjKnjhg8fzkUXXXSwiah79+706NGDLl260L59e/r16xfx9T179uSyyy6joKCA/Px8TjnllIPP3XPPPZx44onk5+fTtWvXgyf/YcOGcc011/DAAw8c7CQGaNiwITNnzuTSSy9l//799O7dm/Hjx1frc02ZMoUrr7ySbt26kZ2dXalc9ZtvvklmZiadO3dm0KBBzJkzh//5n/8hKyuLnJycuCxg41sZahG5BDhHVa/2Ho8ETlTVnwXsMw3XJNQFaAL8SVUP+VQiMg4YB9CmTZtexcXFvsRsjAnNylDXLclUhjpUQ1xw1qkH9ALOA84Gfi0ixx3yItUZqlqoqoUtW7aMf6TGGJPG/GwaKgGOCXicB3wdYp/NqvoD8IOILAa6A5/5GJcxxpgAfl4RLAU6iEg7EakPDAPmBe3zL+AUEaknItnAicAqH2MyxlRTXVvNMF1V5+/k2xWBqu4XkZ8BC3DDRx9X1ZUiMt57/mFVXSUirwDLgQO4IaYr/IrJGFM9DRs2ZMuWLeTm5oYdfmkST1XZsmULDRs2rNLrbM1iY0xUpaWllJSURB2jbxKvYcOG5OXlkZWVVWl7pM7itC0xMXs2TJ4MGzZAmzYwdSqMGJHoqIxJTllZWbRr1y7RYRifpE2JiXXr4A9/gD17XBIYNw6Ki0HV/Rw3zm03xph0kzaJYPly+OUv3c/JkyG4TtPu3W67Mcakm7RJBIVey9jSpa45KJRw240xJpWlTSLIy4NWraCoyPUJhBJuuzHGpLK0SQQi0Lu3SwRTp0J2duXns7PddmOMSTdpkwjANQ+tWgVDhsCMGZCf7xJEfr57bKOGjDHpKK2GjxYWwoED8NFH7qRvJ35jjEnDKwJwzUPGGGOctEoERx7pOo0tERhjTIW0SgTgrgqWLk10FMYYkzzSLhH07g2ffw7btiU6EmOMSQ5plwjK+wnisMynMcakhLRLBL16uZ/WPGSMMU7aJYLcXGjf3jqMjTGmXNolAnDNQ5YIjDHGSdtEsH49bNqU6EiMMSbx0jIR9O7tfn7wQWLjMMaYZJCWiaBnT1djyJqHjDEmTRNB06bQsWPlRDB7NrRtCxkZ7qetVmaMSRe+JgIROUdE1ojIWhGZFOL5gSKyXUSWebc7/YwnUOAMY1u60hiTznxLBCKSCUwHBgGdgeEi0jnErktUtcC73e1XPMEKC+Hrr93Nlq40xqQzP68I+gBrVfULVd0HzAGG+Ph+VdKnj/v57ru2dKUxJr35mQhaA18FPC7xtgU7SUQ+FpGXRaSLj/FU0rs3HH44vPiiLV1pjElvfiYCCbFNgx5/COSranfgz8DckAcSGSciRSJStClOg//r1YNzz4WXXoJ77rGlK40x6cvPRFACHBPwOA/4OnAHVd2hqru8+/OBLBFpEXwgVZ2hqoWqWtiyZcu4BTh4MGze7EpO2NKVxph05edSlUuBDiLSDvgPMAy4PHAHETkS+FZVVUT64BLTFh9jquTss92Vwbx58Lvf2YnfGJOefLsiUNX9wM+ABcAq4GlVXSki40VkvLfbJcAKEfkYeAAYpqrBzUe+adYMBg6EF16orXc0xpjk4+vi9V5zz/ygbQ8H3H8QeNDPGKK54AK48UZYuxaOPTaRkRhjTGKk5cziQBdc4H7aVYExJl2lfSJo1w5OOMESgTEmfaV9IgB3VbB4MXz/faIjMcaY2meJADeMtKwMXnmlYpsVoTPGpAtLBLhyE61auWGkYEXojDHpxRIB7lv/eefByy9DaakVoTPGpBdLBJ7Bg2H7dtdXYEXojDHpxBKB56yzoEkTmDXLitAZY9KLJQJP48YwejQ8/TTcdpsVoTPGpA9LBAEmTIB9+2DHDitCZ4xJH76WmKhrjj8eTjsNHn7YlZywE78xJh3YFUGQCRNg/frKcwqMMSaVWSIIMmQIHH00TJ+e6EiMMaZ2WCIIkpXlJo+98gqsW5foaIwxxn+WCEK45ho3yeyvf010JMYY4z9LBCEcfTRceCE89hjs2ZPoaIwxxl+WCMKYMAG2bnXzCsCK0BljUpcNHw1j4EDo0gXuvx8yM+HaayvqD5UXoQMbYmqMqfvsiiAMEZg4ET7+GH7xCytCZ4xJXZYIIhgxAo44Ar77LvTzVoTOGJMKLBFE0KAB/Pzn4Z+3InTGmFTgayIQkXNEZI2IrBWRSRH26y0iZSJyiZ/xVMf48VC/vusnCGRF6IwxqcK3RCAimcB0YBDQGRguIp3D7Pc7YIFfsdREbi5cfbXrM8jLsyJ0xpjU4+cVQR9grap+oar7gDnAkBD7/Rx4FgjTEp94N9/s1jQePRoOHHC1iCwJGGNShZ+JoDXwVcDjEm/bQSLSGrgQeDjSgURknIgUiUjRpk2b4h5oNMceC0OHwl/+Aj/8UOtvb4wxvvIzEUiIbRr0eBpwm6qWRTqQqs5Q1UJVLWzZsmW84quSX/zCTTB74omEvL0xxvjGz0RQAhwT8DgP+Dpon0JgjoisBy4BHhKRoT7GVG0nnwy9e7uqpBqczowxpg7zMxEsBTqISDsRqQ8MA+YF7qCq7VS1raq2BZ4BJqjqXB9jqjYRN4Lo00/hnXes5IQxJnX4lghUdT/wM9xooFXA06q6UkTGi8h4v97XT5ddBk2bwqRJrsREcbG7OigvOWHJwBhTF4nWsXaOwsJCLSoqStj7X389PPRQ6Ofy892IImOMSTYi8oGqFoZ6zmYWV9G114Z/zkpOGGPqIksEVdStm5tpHIqVnDDG1EWWCKphzJhDt1nJCWNMXRVTIhCRxiKS4d0/TkQGi0iWv6Elr/vvdyf+7GwrOWGMqbqdO+G552D//kRH4sR6RbAYaOjNBH4duBKY5VdQyS47G666yv0RN22ykhPGmNh9/jn07QsXX+wGnyTDeJ1YE4Go6m7gIuDPqnohrpBc2ho3Dvbtq5hpbPMKjDHRzJ/vJqZ++y1cfrlrSfjtbxMdVexLVYqInASMAK6q4mtT0gknQP/+rpnosMPcugW2lKUxJhRVd8K/4w434GTuXNeknJHhVjrMy4NRoxIXX6xXBDcBtwPPe5PC2gNv+hZVHTF1KpSU2FKWxpjwdu+GYcPc+eCyy+Ddd12rgQg89hiccYZran7ttcTFWOUJZV6ncY6q7vAnpMgSPaEs2IUXuuweiogrW22MSS1Ll8KWLXDWWYcuWhXoq69gyBBYtgzuvRduucWdFwJt3w4DBsCXX8L770OnTv7EXOMJZSLylIg0FZHGwKfAGhG5JZ5B1lW/+1345zIyrM/AmFTzySdw2mkwaBB06AD33ecqEwd77z3XH7B2LcybB7feemgSAGjWzPUdZGW5CauJ6DyOtWmos3cFMBSYD7QBRvoVVF1y3HHw05+Gfq6szGoRGZNsysrg44+htLTqr9261a1N0rQpPP44HHOM+5bfurW7Ojj7bHc+OOssGDgQGjd2CeH88yMft3Vr+P3vYfHixJS6jzURZHnzBoYC/1LVUg5dWyBtzZ7thpQ2auQyfqhLReszMCbxXnsNevaEggLo1QuWLIn9tfv3u7b+khI3B+DKK+Gtt2D5crd64Y4drpln5063gNWll7qmni5dYjv+lVdCv37wy1+6ZqdapapRb8ANwH9wVwMC5ANLYnltvG+9evXSZPT736uC6muvqYq4+8E3kURHaUx6+uQT1XPOcf8P27VT/e1vVdu0cY9Hj1b99tvox7jlFrf/I4/4F+fy5ar16qleddWhz23erLp1a/WPDRRpuHN8uCei3YB61X1tTW7Jmgj27FHNz1ft2FE1Ly90IsjPT3SUxqSHvXtVFy1SnTxZtU8f9yXssMNU//AH1R9/dPvs2qV6++2qWVnuuddeC3+8p55y/4cnTPA/9ltvde+1ZIl7/J//qE6cqNq4seqkSdU/bo0TAdAM+CNQ5N3+ADSL5bXxviVrIlBVffNN1QYNVH/yE9VGjSongexs1SefTHSExqS+mTNVc3Lc/7vMTNWTT1a9+27VLVtC779qleoJJ6g2aeKuHIK99ppq/fqqp5ziEozfdu1yVyudO6tee61778xM1SuuUF2xovrHjUcieBb4f0B773YX8Fwsr433LZkTgarq3Lnuj9a5s/tjirgrAUsCxvjv6adVMzJUTz1V9fnnVbdti+11GzaoHnWU+z+7cWPF9rffdl/iunYNn0j8MG+eOzvXr686frzqunU1P2akRBDTPAIRWaaqBdG21YZkm0cQypNPwsiRMHgwPPOMGxZmjPHXK6+4/3N9+sCrr7oBHFXxwQduPH+XLrBoEaxaBaefDkce6UbzHHGEL2GHtXAhdO4MRx8dn+PFY2GaPSLSP+CA/YA98QguFV1xBTz4oBs7fM01iY7GmNT3zjtw0UXuJP7ii1VPAuBGEf3971BU5IaInn02HH64OyHXdhIAOPPM+CWBaGJNBOOB6SKyXkTWAw8CEdbqMtdfD7/6lRsTXJUhasaYqvnoIzjvPDemf8ECV/urugYPdvXDXnvNLUD1+uvuuKmuSiUmRKQpgKruEJGbVHWaX4GFUxeahsrt3g0/+Ql07Ahvvhl6VqExqWzvXlc6YdWqitv69a7JZfx4OOqomh1/wQI3Xv+ww+Dtt+OzSqAq/POfUFgI7dvX/HjJIm5rFqvqDq2oMTSxxpGluOxsd1Xw1lvup5WpNqlM1V39XnedK6TWtq2bZHn88a7ZZvJk1/a+dy/cc4+rvnnFFW7SVXU89pi7Emjf3s3ejddSsSLwX/+VWkkgmposVRn1+62InCMia0RkrYhMCvH8EBFZLiLLRKQosB8iVYwbB7m5bvp4cbGVnDCpp6zMDYo46STX2Tp7tptZ278//PrXrnn0/ffdzNuvvnL3P/sMJkxw/WgnnujKMnz8cWzvp+rKOV99tWtHX7zYlWgwNRBuOFG0G7AhyvOZwDrccNP6wMe4mkWB++RQ0TzVDVgd7X2TffhoKM2bV55TYBPMTKqYO9fNmwH3c/p01R9+iP31O3a4SV6HH+6GWo8d6yZQhXLggOqCBapnnOHe76qrVPfti8/nSAdEGD4acXEZEdlJ6JpCAjSKkmP6AGtV9QvvWHOAIbjqpeVJaFfA/o3DvFedF6oyIcCGDbUbhzFV9a9/wZo1rg5Oy5YV23fsgJtugpkz3UIr//ynK8keqSRzKE2awMSJ7vi/+Q38+c8wZw5ccIEbOnn88a4s8/vvu07clSvdcM4//cktBmX9bnESLkPU9AZcAjwa8Hgk8GCI/S4EVgNbgZPCHGsc3qzmNm3a+JYx/ZKfb1cEpu6ZNq3i32qDBq4mT1GR6uLFqm3buolbkyfHd7btunWqI0e6ekDB/1+6dVOdNauiRISpGiJcEdSkjyCaULn6kG/8qvq8qnbCVTa9J9SBVHWGqhaqamHLwK8ldcTUqa7TLFB2tttuTHXt2xf+arMmVN3ghptucp28H33kVtB65hk3kmbAADfoYckS9y2+fv34vXf79vC3v8EXX8CuXW6S15NPulF3y5a5Kp8NGsTv/Yzj57rDJUDgCNw84OtwO6vqYhH5iYi0UNXNPsZV68rXLb75Zti0ydUof/hhW8/YhKfqOlY/+8yd7Lduhe+/h40b4fPP3W39etdRe955brnUgQNr3lSyf79bHOXxx92Ahocecs0906fDf/83zJoF27a598vJqfnnjKRxY1cyumdPf9/H+JsIlgIdRKQdroT1MODywB1E5FhgnaqqiPTEdSrXdiXuWjFihLv95jduJMWKFYmOyCSbTz5xo2jefx/+/W/49ttD98nJcati9eoFw4e7pVAfecSNy+/Z033ZuPjiQ69Ag23e7FbFeukl+PprN6Rz7153kt+wAe68E6ZMqZxYmjWDG2+M5yc2ycK3RKCq+0XkZ8AC3Aiix9UtfD/ee/5h4GJglIiU4kpWXOa1ZaWsyZPdf7zf/c5NprH/WObLL92Xg6eeclcCHTu68gZ9+sAJJ0CLFtC8uSt30LDhoa+/4w7XfPLHP7oaVxMmuI7byy934/nBNbWsWuW+gLzyiltA/cABV8KgY0eXYBo0cLd77oFRo2r3d2ASq8qL1ydaXZpZHE5ZmZsNOXeuq21y2WWJjsjUNlX3zfv++yuaX2680TW5VLcb7MAB15b+1FPw7LNutaxmzdwM98BlGQsKXCmFwYPdVYSNvEkPkWYWWyJIkD173CSaf//bzTw+6aRER2T89OOPrp393XfdYuZr17oTdEYGjB0Ld90FeXnxe7+9e+Hll13zT25uxTDMjh1dcjDpJ1Ii8LOPwETw3HOus6+0FE45BR54wF3Sm7phzx7Xnt+6NfTo4To2w3nzTVdX57PP4Ljj3O300+HYY93M2I4d4x9fgwaugubQofE/tkk9lggSYPZsNyJj9273uKzMTY7JybG22bpg504YMsSd4MF9q+/c2Q2t7NTJdeYee6wrhHbnna7EQvv2rkDaT3+a0NCNCcmahhKgbVtXbyhY06auXdckr++/h3PPhaVL3RDgI49095cudWPev/uu8v716sGtt7oO3WgjeYzxkzUNJZlwpSV27IBWrdzQvjZt3IQzm2uQPDZtct/oP/20oqQCwPnnV+yzfTusW+f6ADZsgEGD3GIpxiQzuyJIgHBXBMGystxVwtatlhgSadMmN4t28mT3d3v+eTe805i6JG7rEZj4mDr10KX0Qg3hKy2FLVusdHVtKy11o23Gj3dt/61auUla337rxuBbEjCpxhJBAowYATNmuIU5RNzPWC7Mdu9230pN/B04ULGoylFHubINTz3lrt7uvdcN+/zmG1dnx5hUY30ECVJecqJcrM1FVrq66vbvh7/+1dXuyc93v+v8fFdOYckSd3vnHfc4O9tNtLr8cvfNP54F1YxJVpYIksTUqZWHlIYTr+X40sXHH7sJWx9+6Ebw7N9/6D6dOsEll7ix/Rdc4H8xNWOSjSWCJFF+dTB5svvW37y5G6++b1/FPhkZbltGhnUeR7N3ryvwd++9bmbtM8+4UT4bN7orr+JiN5yzX7/ql3QwJlXYqKEkNnt2xUiVrKzK9WLANWPMmGHJINiSJa6U8qpVboLe/fe7xGpMOrNRQ3XUiBGuDIWq68AMlq6dx6puNNWBA5W3b93qFjQfMMD9bl5+2c3qtSRgTGTWNFRHfPVV6O3Fxa75KFSn5jffuNWeNm50NW0GDoxcEydZFRe7aporVrjJXKtWucl3OTluvdyCAldO+U9/csng1ltdaYe6+FmNSQRLBHVEmzbhRxW1aOG+BZ92mrtt3AiPPgovvODqGDVoANOmuWTRv7/bt3Vrd5Vx1FFuBE1ubvxjVnXfyu++243IufhiV3K7a9fopY9LS+HFF13T14IF7lhHHOHG9Y8cCe3auauljz92tfh37IATT4SFC11yMMbEzvoI6ojgQnXgRsE0auQ6kINHxLRqBWPGuLVm27SBt992J9QFC9xKWIEyM91qV7ff7k60sSopcespPPOMK7B26qnuqqOw0L3fHXfAe++5k3b79q5I24EDbpROv37uZP/jj+62d6+7sim/FRe7uj2tW7tRP2PHumGfoai6yV6tWrmOdGPMoWw9ghRR3nkcblRRw4buhHnWWa4wWrgx8Hv3uhPnxo3utnixG2e/Z48bWTNpkjuZh/rWvnGjm3X71FPuxK4KvXu715Yvv1m/vosrL8+tvHXlla6z+7vvXPntf/zDNe80bFhxK18dKyvLvb55cxg2zNXqqWfXrcbUmCWCFBRuAlp+vmsyqarNm10b+5//7AqnNW/ulkrs29ddJSxd6q4mli93+//kJ66JZsQIV3IZKmryLFninr/66tBLKxpjap8lghSUkRG6LIXIoaNpqmL7dldZ87333Oppn37q3icry/UvnH22u3XvbkscGlOXWBnqFBSu87imM4+bNXPf5K++2j3esQNWr3ZXBTbj1pjU5GvXmoicIyJrRGStiEwK8fwIEVnu3d4Vke5+xpNKQlUwzc522+OpaVPXRGRJwJjU5VsiEJFMYDowCOgMDBeR4DEpXwKnqmo34B5ghl/xpJpQFUxHj3adyRkZrg/BSlYbY2Lh5xVBH2Ctqn6hqvuAOcCQwB1U9V1V/d57+H9Ano/xpJzymccHDrgrgSeecM1Ftn6BMaYq/EwErYHA+bAl3rZwrgJe9jGelDZ58qGVS6tagmL2bHclYVcUxqQXPzuLQ40pCTlESUROwyWC/mGeHweMA2hjdZhDCrdOQazrFwRPWCu/ogAramdMqvPziqAEOCbgcR7wdfBOItINeBQYoqpbQh1IVWeoaqGqFra0msEhhcuPGRnhv+EHXgGMHl3zKwpjTN3kZyJYCnQQkXYiUh8YBswL3EFE2gDPASNV9TMfY0l5oUYRgas1VN5ncOWVri5RRob7OXZsRZ9CWVno49qKaMakPt+ahlR1v4j8DFgAZAKPq+pKERnvPf8wcCeQCzwkbnbS/nATHkxkwQvbZGQcenIvLXXlm6HiZzTWEmdM6rOZxSkq3MzjqsjOdk1G8+e75GKrohlTd9nCNGmout/kMzMrz0sIHpIa2LxkI4uMSQ2WCFJUuD6DSLKz3Yn/wAE3P2H+/EM7kMubl2yugjGpwxJBigqeeZybe2hZ6qwst738CiB4/eNYOoptZJExdZ8lghQWOPN482Z4/PHKJSlmznTby68Agtv+Y21eKi62piJj6jJLBGkkMDGEOvEHq0rzkjUVGVN3WSIwYcXSvBQsuKnIylYYk/wsEZiIIjUvhVPet1BetsIK4RmT3CwRmCoJTAz5+aH3Ke9biEchPGOM/ywRmGqLtjhOTQvhGWNqhyUCU22hFscJHIIabtRR4HbrQzAm8SwRmBqJNBIp2hWD9SEYkxwsEZi4CvyGP3myK1MRbjlNK31tTHLwc2Eak2ZCLW7zxBMVzUXBz1vpa2OSg10RmLiJNkoo1POhRFpMxxgTf5YITNxEGyUU6zf9wMV0QvUZWAezMfFlicDETbRRQuGeLy99nZl56HOhZipbB7Mx8WWJwMRNtFFC4Z4vL3194EDo4wZeScQySc2uGIypGksEJm6izSuIx7yDaM1PdsVgTNXZUpUmaQSPKgK3ZkLTprB1q0sIu3aFXm85P9/NY2jb1p38wz1vTLqypSpNnRCq2qlI5RXRduw4tAJqMpS1sOYoU5dZIjBJJXCmck4O7NtX+fnSUmjSJPwktYww/6Kru4ZzLKw5ytR1viYCETlHRNaIyFoRmRTi+U4i8p6I7BWRX/oZi6l7wn2L37q1IllMneo6m8tPwqEmqQVeMfjBqqyaus63RCAimcB0YBDQGRguIp2DdtsK3ADc51ccpu6KpfM43CS18iGpodZijjersmrqOj+vCPoAa1X1C1XdB8wBhgTuoKrfqepSoNTHOEwdFW04KoQ/2ZYPR41lSc6aiiVhGZPM/EwErYGvAh6XeNuqTETGiUiRiBRt2rQpLsGZ5BdtuCkkR6nrWBKWMcnMz0QQajHDao1VVdUZqlqoqoUtW7asYVimLolU5hqSo9R1LAnLmGTmZyIoAY4JeJwHfO3j+5k0FO0kHK4jd/To+F4hREtYxiQzPxPBUqCDiLQTkfrAMGCej+9n0lSkk3C4PoRIhe2iNSXVlTkDdSVOkwRU1bcbcC7wGbAOmOxtGw+M9+4fibty2AFs8+43jXTMXr16qTGxys9Xdaf8yLf8fLf/k0+qZmdXfi47222P5flwnnzSvYeI+xlt/+oIfI/cXNX69asep0ldQJGGO1eHeyJZb5YITFWEOnGHu4moZmZGThThEkv587HGUNOTcnBiue662D5npDhNaouUCKzWkEl5s2e7voING1wzSbiV0SIRcU1PGRnulBru+aq8Z3XrH4WqySQSOq5ocZr0YbWGTFoL7EN44olDRxnFItqaCsHDVQNHKsV7Sc5QHeCxfp+zuQ0mFEsEJq0EjzKKRSxrKgTOGYh1Sc7qznWobgKxuQ0mrHBtRsl6sz4CE0/h2vwzM8N37Ebr+BWJ3lZfkw7ocDEHv29Wlus0DuxH8LvD2iQvIvQR2BWBSWvRVk0rb8MP/LYOkecMRFuSM9a5DuGK1oWLefz4yvMpZs6EzZtDF+ezCqmmknAZIllvdkVg4i3SN/zqjPip6msiXUGE+zZf1W/31RntFE1tDIk18YMNHzWmeqp7Aq3KSTLWuQ41GX4aLtmIxH6MRMxTsGQTP5YIjKmmeJxAo6nKXIfqfpuv6RVBrDFW9Qoj3ldjJrxIicD6CIyJwK8S04GjhCZPdrWPqjKSCao2eqg6FVIDYxw9OraRUFWJKVpBQFvwpxaFyxDJerMrAlOb/JoVHOmYVS2LUZX3jbWZpbpXKZFGWwWLNmIrUr+JqTqsaciY6ot3O3W0ZppYTsLxaCIJVaai/HG4Uhvx7MeIZZhtTROg9TFUsERgTBKJpd8h0kk6Hie06n7jD7wFzlMIlzhyc+ObbKqSAJO5QGA0fsRgicCYJOLHUM54xVDdpp/qfruP9RbrCTHwBBqtgGC41ye6g9qvGCIlAussNqaWJcPSltUpUxE80S6WJUNjUT7RLjMz9PP5+eEn9wWvIxFLjafi4srHmDAhcqd4bXdQJ6STPFyGSNabXRGYVJDo5odYrwhi7fytSVNTeZNYTdeCiPUzVefqJVIHdbz/ln4NWcaahowxgfzokA4+IebmxnaSDWyqiXRSjdakFssJvrpNWOESYizNOFVNFH41HVoiMMYcIhk6pKuSbKINKQ3XJxB4Eq9OEogUc3VGgIX6zLUxa9sSgTEmIeKZbOJRiqOqTWLROpzjkZxCrS4XXDnW71FD1llsjPFN4KJA69fDQw9FrtwaSahO9lDCVXmN9RiBneLhVnMrLnadyxkRzqCq4Tusy8rc88XF8PDDh3YOl5ZCTk5sneTxUC++hzPGGH8Elu3esMGdSEOJdAIPPkabNnDuuTB/fsXjqVMr9mvTxp2sQ4l0oq+KcJ+jfGRX8NKk5aU4Aj9PTdmaxcaYOqlt29An6equBR1KqPWhQ8nMdMknnqfT8s8Rr8+ZsDWLReQcEVkjImtFZFKI50VEHvCeXy4iPf2MxxiTOmpjPkasS5uWX4Xk54d+PtpcieBjB36OcHM+qrtkaSi+JQIRyQSmA4OAzsBwEekctNsgoIN3Gwf8xa94jDGpJfgkHapPIF7vU96vEe5EXz6hLtqKd088EdvqcoGfw68KuJWE60Wu6Q04CVgQ8Ph24Pagff4KDA94vAY4KtJxbdSQMSZR4jFvoKrzCuJVcoIIo4b87CxuDXwV8LgEODGGfVoDGwN3EpFxuCsG2sQ1DRpjTOxCdTYHdi6X7xPpqiTa89V5z5ryMxGEalEL7kqJZR9UdQYwA1xncc1DM8aY6qnqibwuvKefncUlwDEBj/OAr6uxjzHGGB/5mQiWAh1EpJ2I1AeGAfOC9pkHjPJGD/UFtqvqxuADGWOM8Y9vTUOqul9EfgYsADKBx1V1pYiM955/GJgPnAusBXYDV/oVjzHGmNB8nVmsqvNxJ/vAbQ8H3Ffgej9jMMYYE5nVGjLGmDRX50pMiMgmIEz1j6haAJvjGI5f6kKcFmN8WIzxYTFGl6+qLUM9UecSQU2ISJGGqbWRTOpCnBZjfFiM8WEx1ow1DRljTJqzRGCMMWku3RLBjEQHEKO6EKfFGB8WY3xYjDWQVn0ExhhjDpVuVwTGGGOCWCIwxpg0lzaJINpqaYkgIo+LyHcisiJgW3MReU1EPvd+Hp7gGI8RkTdFZJWIrBSRG5MtThFpKCLvi8jHXoz/L9liDIg1U0Q+EpEXkzjG9SLyiYgsE5GiZIxTRA4TkWdEZLX3b/OkZIpRRDp6v7/y2w4RuSmZYgyUFokgxtXSEmEWcE7QtknA66raAXjde5xI+4FfqOrxQF/geu93l0xx7gVOV9XuQAFwjlfEMJliLHcjsCrgcTLGCHCaqhYEjHtPtjj/BLyiqp2A7rjfadLEqKprvN9fAdALV0vt+WSKsZJwK9ak0o0YVktLYGxtgRUBjw+u0gYcBaxJdIxB8f4LOCtZ4wSygQ9xiyAlVYy4MuuvA6cDLybr3xtYD7QI2pY0cQJNgS/xBrskY4xBcf0UeCeZY0yLKwLCr4SWjI5QrxS397NVguM5SETaAj2Af5NkcXpNLsuA74DXVDXpYgSmAbcCBwK2JVuM4BaHelVEPvBWB4TkirM9sAmY6TWzPSoijZMsxkDDgL9795MyxnRJBDGthGbCE5Ec4FngJlXdkeh4gqlqmbrL8Dygj4ickOCQKhGR84HvVPWDRMcSg36q2hPXlHq9iAxIdEBB6gE9gb+oag/gB5KliSWItxbLYOCfiY4lknRJBHVpJbRvReQoAO/ndwmOBxHJwiWB2ar6nLc56eIEUNVtwCJc30syxdgPGCwi64E5wOki8iTJFSMAqvq19/M7XLt2H5IrzhKgxLvqA3gGlxiSKcZyg4APVfVb73Eyxpg2iSCW1dKSxTxgtHd/NK5NPmFERIDHgFWq+seAp5ImThFpKSKHefcbAWcCq0miGFX1dlXNU9W2uH9/b6jqFSRRjAAi0lhEmpTfx7VvryCJ4lTVb4CvRKSjt+kM4FOSKMYAw6loFoLkjDE9Oou9jplzgc+AdcDkRMfjxfR3YCNQivuWcxWQi+tQ/Nz72TzBMfbHNaMtB5Z5t3OTKU6gG/CRF+MK4E5ve9LEGBTvQCo6i5MqRlz7+8febWX5/5UkjLMAKPL+5nOBw5MwxmxgC9AsYFtSxVh+sxITxhiT5tKlacgYY0wYlgiMMSbNWSIwxpg0Z4nAGGPSnCUCY4xJc5YIjPGISFlQxci4zVYVkbaBVWaNSSb1Eh2AMUlkj7oyFcakFbsiMCYKrz7/77w1D94XkWO97fki8rqILPd+tvG2HyEiz3vrI3wsIid7h8oUkUe8NRNe9WZBIyI3iMin3nHmJOhjmjRmicCYCo2CmoYuC3huh6r2AR7EVRHFu/83Ve0GzAYe8LY/ALylbn2EnrgZugAdgOmq2gXYBlzsbZ8E9PCOM96fj2ZMeDaz2BiPiOxS1ZwQ29fjFr75wivA942q5orIZlxt+VJv+0ZVbSEim4A8Vd0bcIy2uPLYHbzHtwFZqvobEXkF2IUrlTBXVXf5/FGNqcSuCIyJjYa5H26fUPYG3C+joo/uPNwKer2AD0TE+u5MrbJEYExsLgv4+Z53/11cJVGAEcDb3v3Xgevg4II5TcMdVEQygGNU9U3cojWHAYdclRjjJ/vmYUyFRt4qZ+VeUdXyIaQNROTfuC9Pw71tNwCPi8gtuBWzrvS23wjMEJGrcN/8r8NVmQ0lE3hSRJrhFlC6X92aCsbUGusjMCYKr4+gUFU3JzoWY/xgTUPGGJPm7IrAGGPSnF0RGGNMmrNEYIwxac4SgTHGpDlLBMYYk+YsERhjTJr7//BwPpBBy0z/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(75)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluation Step\n",
    "- Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2946 - accuracy: 0.9357\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.29461875557899475, 0.9357143044471741]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "- Prediction should be > **92%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (predictions > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[47,  8],\n",
       "       [ 1, 84]])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.confusion_matrix(\n",
    "    test_label, y_pred, num_classes=2, weights=None, dtype=tf.dtypes.int32,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    " # It will evaluate the logical expression y_predict>0.25 and return True or False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
